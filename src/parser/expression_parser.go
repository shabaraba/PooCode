package parser

import (
	"github.com/uncode/ast"
	"github.com/uncode/logger"
	"github.com/uncode/token"
)

// parseExpression ã¯å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseExpression(precedence int) ast.Expression {
	prefix := p.prefixParseFns[p.curToken.Type]
	if prefix == nil {
		p.noPrefixParseFnError(p.curToken.Type)
		return nil
	}
	leftExp := prefix()

	for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
		infix := p.infixParseFns[p.peekToken.Type]
		if infix == nil {
			return leftExp
		}

		p.nextToken()
		leftExp = infix(leftExp)
	}

	return leftExp
}

// parseExpressionStatement ã¯å¼æ–‡ã‚’è§£æã™ã‚‹
func (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
	stmt := &ast.ExpressionStatement{Token: p.curToken}

	stmt.Expression = p.parseExpression(LOWEST)

	if p.peekTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

// parsePrefixExpression ã¯å‰ç½®å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePrefixExpression() ast.Expression {
	expression := &ast.PrefixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
	}

	p.nextToken()
	expression.Right = p.parseExpression(PREFIX)

	return expression
}

// parseInfixExpression ã¯ä¸­ç½®å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
	expression := &ast.InfixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
		Left:     left,
	}

	precedence := p.curPrecedence()
	p.nextToken()
	expression.Right = p.parseExpression(precedence)

	return expression
}

// parseGroupedExpression ã¯æ‹¬å¼§ã§å›²ã¾ã‚ŒãŸå¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseGroupedExpression() ast.Expression {
	p.nextToken()

	exp := p.parseExpression(LOWEST)

	if !p.expectPeek(token.RPAREN) {
		return nil
	}

	return exp
}

// parseIndexExpression ã¯æ·»å­—å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseIndexExpression(left ast.Expression) ast.Expression {
	exp := &ast.IndexExpression{Token: p.curToken, Left: left}

	p.nextToken()
	
	// ã‚¹ãƒ©ã‚¤ã‚¹è¡¨è¨˜ã®å‡¦ç† (array[start..end])
	if p.curTokenIs(token.DOTDOT) {
		// array[..end] ã®å½¢å¼
		rangeExp := &ast.RangeExpression{
			Token: p.curToken,
			Start: nil,
		}
		
		p.nextToken() // ..ã®æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¸
		
		// çµ‚äº†å€¤ã‚’è§£æ
		if !p.curTokenIs(token.RBRACKET) {
			rangeExp.End = p.parseExpression(LOWEST)
			if !p.expectPeek(token.RBRACKET) {
				return nil
			}
		} else {
			// array[..] ã®å½¢å¼ï¼ˆä¸¡æ–¹ãªã—ï¼‰
			if !p.expectPeek(token.RBRACKET) {
				return nil
			}
		}
		
		// ç¯„å›²å¼ã‚’ç›´æ¥è¿”ã™
		return rangeExp
	}
	
	// é€šå¸¸ã®æ·»å­—ã¾ãŸã¯ã‚¹ãƒ©ã‚¤ã‚¹è¡¨è¨˜ã®é–‹å§‹å€¤
	exp.Index = p.parseExpression(LOWEST)
	
	// array[start..end] ã¾ãŸã¯ array[start..] ã®å½¢å¼ã®å ´åˆ
	if p.peekTokenIs(token.DOTDOT) {
		p.nextToken() // ..ã¸
		rangeExp := &ast.RangeExpression{
			Token: p.curToken,
			Start: exp.Index, // ã™ã§ã«è§£æã—ãŸé–‹å§‹å€¤
		}
		
		p.nextToken() // ..ã®æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¸
		
		// çµ‚äº†å€¤ã‚’è§£æ
		if !p.curTokenIs(token.RBRACKET) {
			rangeExp.End = p.parseExpression(LOWEST)
			if !p.expectPeek(token.RBRACKET) {
				return nil
			}
		} else {
			// array[start..] ã®å½¢å¼ï¼ˆçµ‚äº†å€¤ãªã—ï¼‰
			if !p.expectPeek(token.RBRACKET) {
				return nil
			}
		}
		
		// ç¯„å›²å¼ã‚’ç›´æ¥è¿”ã™
		return rangeExp
	}
	
	// é€šå¸¸ã®æ·»å­—ã‚¢ã‚¯ã‚»ã‚¹ã®å ´åˆ
	if !p.expectPeek(token.RBRACKET) {
		return nil
	}

	return exp
}

// parsePropertyExpression ã¯ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚¢ã‚¯ã‚»ã‚¹å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePropertyExpression(left ast.Expression) ast.Expression {
	exp := &ast.PropertyAccessExpression{
		Token:  p.curToken,
		Object: left,
	}

	p.nextToken()
	exp.Property = p.parseExpression(PROPERTY)

	return exp
}

// parsePipeExpression ã¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePipeExpression(left ast.Expression) ast.Expression {
	// ãƒ‘ã‚¤ãƒ—æ¼”ç®—å­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
	pipeToken := p.curToken
	
	// ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
	logger.ParserDebug("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼ã®è§£æé–‹å§‹ï¼šæ¼”ç®—å­=%s, å·¦è¾º=%s", pipeToken.Literal, left.String())
	
	// ãƒ‘ã‚¤ãƒ—æ¼”ç®—å­ã®å„ªå…ˆé †ä½ã‚’å–å¾—
	precedence := p.curPrecedence()
	
	// æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«é€²ã‚€
	p.nextToken()
	
	// ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
	logger.ParserDebug("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å³è¾ºã®è§£æä¸­ï¼šç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³=%s, æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³=%s", 
		p.curToken.Literal, p.peekToken.Literal)
	
	// ãƒ‘ã‚¤ãƒ—ã®å³å´ã®å¼ã‚’è§£æã™ã‚‹
	// å³å´ã¯è­˜åˆ¥å­ã¾ãŸã¯é–¢æ•°å‘¼ã³å‡ºã—ã®ã¯ãš
	rightExp := p.parseExpression(precedence)
	
	// è§£æã•ã‚ŒãŸå³è¾ºã®å¼ã‚’è¨˜éŒ²
	logger.ParserDebug("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å³è¾ºã®è§£æçµæœï¼šã‚¿ã‚¤ãƒ—=%T, å€¤=%s", rightExp, rightExp.String())
	
	// ãƒ‘ã‚¤ãƒ—ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†ã‘ã‚‹
	if pipeToken.Type == token.PIPE_PAR {
		// ä¸¦åˆ—ãƒ‘ã‚¤ãƒ— (|) ã®å ´åˆ
		return &ast.InfixExpression{
			Token:    pipeToken,
			Operator: pipeToken.Literal,
			Left:     left,
			Right:    rightExp,
		}
	} else {
		// |> æ¼”ç®—å­ã®å ´åˆï¼ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰
		
		// è­˜åˆ¥å­ã®å¾Œã«å¼•æ•°ãŒç¶šãå ´åˆã®ç‰¹åˆ¥å‡¦ç†
		if ident, ok := rightExp.(*ast.Identifier); ok {
			logger.ParserDebug("è­˜åˆ¥å­ '%s' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...", ident.Value)
			
			// æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒè­˜åˆ¥å­ã€æ•´æ•°ã€æ–‡å­—åˆ—ã€é…åˆ—ãªã©ã€æœ‰åŠ¹ãªå¼•æ•°ã¨ãªã‚Šã†ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚ã‚Œã°
			// ãã‚Œã‚’é–¢æ•°ã®å¼•æ•°ã¨ã—ã¦å‡¦ç†ã™ã‚‹
			if !p.peekTokenIs(token.PIPE) && !p.peekTokenIs(token.PIPE_PAR) && 
			   !p.peekTokenIs(token.ASSIGN) && !p.peekTokenIs(token.SEMICOLON) &&
			   !p.peekTokenIs(token.RPAREN) && !p.peekTokenIs(token.RBRACE) &&
			   !p.peekTokenIs(token.RBRACKET) && !p.peekTokenIs(token.COMMA) {
				
				logger.ParserDebug("å¼•æ•°ã¨ã—ã¦å‡¦ç†å¯èƒ½ãªãƒˆãƒ¼ã‚¯ãƒ³ãŒç¶šãã¾ã™: %s (%s)", p.peekToken.Literal, p.peekToken.Type)
				
				// æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
				p.nextToken()
				
				// å¼•æ•°ã‚’åé›†
				var args []ast.Expression
				
				// æœ€åˆã®å¼•æ•°ã‚’è§£æ
				if p.curToken.Type == token.PIZZA {
					// ğŸ•ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¼•æ•°ã®å ´åˆã€ç‰¹åˆ¥å‡¦ç†
					arg := &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
					args = append(args, arg)
					logger.ParserDebug("ğŸ•ãŒç¬¬1å¼•æ•°ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
				} else {
					// é€šå¸¸ã®å¼•æ•°è§£æ
					arg := p.parseExpression(LOWEST)
					args = append(args, arg)
					logger.ParserDebug("è§£æã•ã‚ŒãŸç¬¬1å¼•æ•°: %s (ã‚¿ã‚¤ãƒ—: %T)", arg.String(), arg)
				}
				
				// ã•ã‚‰ã«å¼•æ•°ãŒã‚ã‚‹å ´åˆ
				for p.peekTokenIs(token.IDENT) || p.peekTokenIs(token.INT) || 
					p.peekTokenIs(token.STRING) || p.peekTokenIs(token.BOOLEAN) ||
					p.peekTokenIs(token.PIZZA) || p.peekTokenIs(token.LBRACKET) {
					
					p.nextToken()
					
					if p.curToken.Type == token.PIZZA {
						// ğŸ•ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¼•æ•°ã®å ´åˆã€ç‰¹åˆ¥å‡¦ç†
						arg := &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
						args = append(args, arg)
						logger.ParserDebug("ğŸ•ãŒè¿½åŠ ã®å¼•æ•°ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
					} else {
						// é€šå¸¸ã®å¼•æ•°è§£æ
						arg := p.parseExpression(LOWEST)
						args = append(args, arg)
						logger.ParserDebug("è§£æã•ã‚ŒãŸè¿½åŠ å¼•æ•°: %s (ã‚¿ã‚¤ãƒ—: %T)", arg.String(), arg)
					}
					
					// ãƒ‘ã‚¤ãƒ—ã‚„ã‚»ãƒŸã‚³ãƒ­ãƒ³ãŒæ¥ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
					if p.peekTokenIs(token.PIPE) || p.peekTokenIs(token.PIPE_PAR) || 
					   p.peekTokenIs(token.ASSIGN) || p.peekTokenIs(token.SEMICOLON) {
						break
					}
				}
				
				// CallExpressionã‚’ç”Ÿæˆ
				callExpr := &ast.CallExpression{
					Token:     pipeToken,
					Function:  ident,
					Arguments: args,
				}
				
				// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼ã®å³è¾ºã¨ã—ã¦CallExpressionã‚’ä½¿ç”¨
				logger.ParserDebug("é–¢æ•°å‘¼ã³å‡ºã—å¼ã‚’ç”Ÿæˆ: %s(å¼•æ•°: %då€‹)", ident.Value, len(args))
				return &ast.InfixExpression{
					Token:    pipeToken,
					Operator: pipeToken.Literal,
					Left:     left,
					Right:    callExpr,
				}
			} else {
				logger.ParserDebug("å¼•æ•°ãªã—ã®è­˜åˆ¥å­: %sã€æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³: %s", ident.Value, p.peekToken.Literal)
			}
			
			// å¼•æ•°ãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
			return &ast.InfixExpression{
				Token:    pipeToken,
				Operator: pipeToken.Literal,
				Left:     left,
				Right:    rightExp,
			}
		}
		
		// é€šå¸¸ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼ã¨ã—ã¦å‡¦ç†
		return &ast.InfixExpression{
			Token:    pipeToken,
			Operator: pipeToken.Literal,
			Left:     left,
			Right:    rightExp,
		}
	}
}

// parseAssignExpression ã¯ä»£å…¥å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseAssignExpression(left ast.Expression) ast.Expression {
	expression := &ast.InfixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
		Left:     left,
	}

	p.nextToken()
	expression.Right = p.parseExpression(LOWEST)

	return expression
}

// parseExpressionList ã¯å¼ã®ãƒªã‚¹ãƒˆã‚’è§£æã™ã‚‹
func (p *Parser) parseExpressionList(end token.TokenType) []ast.Expression {
	list := []ast.Expression{}

	if p.peekTokenIs(end) {
		p.nextToken()
		return list
	}

	p.nextToken()
	list = append(list, p.parseExpression(LOWEST))

	for p.peekTokenIs(token.COMMA) {
		p.nextToken()
		p.nextToken()
		list = append(list, p.parseExpression(LOWEST))
	}

	if !p.expectPeek(end) {
		return nil
	}

	return list
}
