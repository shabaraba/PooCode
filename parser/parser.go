package parser

import (
	"fmt"
	"strconv"

	"github.com/uncode/ast"
	"github.com/uncode/lexer"
	"github.com/uncode/token"
)

// æ¼”ç®—å­ã®å„ªå…ˆé †ä½
const (
	_ int = iota
	LOWEST
	PIPE
	ASSIGN      // >>
	LOGICAL     // && ||
	EQUALS      // == !=
	LESSGREATER // > < >= <=
	SUM         // + -
	PRODUCT     // * / %
	PREFIX      // -X or !X
	CALL        // myFunction(X)
	INDEX       // array[index]
	PROPERTY    // obj.prop or obj's prop
)

// æ¼”ç®—å­ã®å„ªå…ˆé †ä½ãƒãƒƒãƒ—
var precedences = map[token.TokenType]int{
	token.ASSIGN:       ASSIGN,
	token.EQ:           EQUALS,
	token.NOT_EQ:       EQUALS,
	token.LT:           LESSGREATER,
	token.GT:           LESSGREATER,
	token.LE:           LESSGREATER,
	token.GE:           LESSGREATER,
	token.PLUS:         SUM,
	token.MINUS:        SUM,
	token.SLASH:        PRODUCT,
	token.ASTERISK:     PRODUCT,
	token.MODULO:       PRODUCT,
	token.LPAREN:       CALL,
	token.LBRACKET:     INDEX,
	token.DOT:          PROPERTY,
	token.APOSTROPHE_S: PROPERTY,
	token.AND:          LOGICAL,
	token.OR:           LOGICAL,
	token.PIPE:         PIPE,
	token.PIPE_PAR:     PIPE,
}

type (
	prefixParseFn func() ast.Expression
	infixParseFn  func(ast.Expression) ast.Expression
)

// Parser ã¯ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’è§£æã—ã¦æŠ½è±¡æ§‹æ–‡æœ¨ã‚’ç”Ÿæˆã™ã‚‹
type Parser struct {
	l         *lexer.Lexer
	tokens    []token.Token
	position  int
	curToken  token.Token
	peekToken token.Token
	errors    []string

	prefixParseFns map[token.TokenType]prefixParseFn
	infixParseFns  map[token.TokenType]infixParseFn
}

// NewParser ã¯æ–°ã—ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ç”Ÿæˆã™ã‚‹
func NewParser(tokens []token.Token) *Parser {
	p := &Parser{
		tokens:         tokens,
		position:       0,
		errors:         []string{},
		prefixParseFns: make(map[token.TokenType]prefixParseFn),
		infixParseFns:  make(map[token.TokenType]infixParseFn),
	}

	// å‰ç½®æ¼”ç®—å­ã®è§£æé–¢æ•°ã‚’ç™»éŒ²
	p.registerPrefix(token.IDENT, p.parseIdentifier)
	p.registerPrefix(token.INT, p.parseIntegerLiteral)
	p.registerPrefix(token.FLOAT, p.parseFloatLiteral)
	p.registerPrefix(token.STRING, p.parseStringLiteral)
	p.registerPrefix(token.BOOLEAN, p.parseBooleanLiteral)
	p.registerPrefix(token.MINUS, p.parsePrefixExpression)
	p.registerPrefix(token.NOT, p.parsePrefixExpression)
	p.registerPrefix(token.BANG, p.parsePrefixExpression)
	p.registerPrefix(token.LPAREN, p.parseGroupedExpression)
	p.registerPrefix(token.LBRACKET, p.parseArrayLiteral)
	p.registerPrefix(token.FUNCTION, p.parseFunctionLiteral)
	p.registerPrefix(token.CLASS, p.parseClassLiteral)
	p.registerPrefix(token.PIZZA, p.parsePizzaLiteral)
	p.registerPrefix(token.POO, p.parsePooLiteral)

	// ä¸­ç½®æ¼”ç®—å­ã®è§£æé–¢æ•°ã‚’ç™»éŒ²
	p.registerInfix(token.PLUS, p.parseInfixExpression)
	p.registerInfix(token.MINUS, p.parseInfixExpression)
	p.registerInfix(token.SLASH, p.parseInfixExpression)
	p.registerInfix(token.ASTERISK, p.parseInfixExpression)
	p.registerInfix(token.MODULO, p.parseInfixExpression)
	p.registerInfix(token.EQ, p.parseInfixExpression)
	p.registerInfix(token.NOT_EQ, p.parseInfixExpression)
	p.registerInfix(token.LT, p.parseInfixExpression)
	p.registerInfix(token.GT, p.parseInfixExpression)
	p.registerInfix(token.LE, p.parseInfixExpression)
	p.registerInfix(token.GE, p.parseInfixExpression)
	p.registerInfix(token.AND, p.parseInfixExpression)
	p.registerInfix(token.OR, p.parseInfixExpression)
	p.registerInfix(token.LPAREN, p.parseCallExpression)
	p.registerInfix(token.LBRACKET, p.parseIndexExpression)
	p.registerInfix(token.DOT, p.parsePropertyExpression)
	p.registerInfix(token.APOSTROPHE_S, p.parsePropertyExpression)
	p.registerInfix(token.ASSIGN, p.parseAssignExpression)
	p.registerInfix(token.PIPE, p.parsePipeExpression)
	p.registerInfix(token.PIPE_PAR, p.parsePipeExpression)

	// æœ€åˆã®2ã¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿è¾¼ã‚€
	if len(tokens) > 0 {
		p.curToken = tokens[0]
		if len(tokens) > 1 {
			p.peekToken = tokens[1]
		}
	}

	return p
}

// Errors ã¯ãƒ‘ãƒ¼ã‚¹ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
func (p *Parser) Errors() []string {
	return p.errors
}

// nextToken ã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«é€²ã‚€
func (p *Parser) nextToken() {
	p.position++
	if p.position >= len(p.tokens) {
		p.curToken = token.Token{Type: token.EOF, Literal: ""}
		p.peekToken = token.Token{Type: token.EOF, Literal: ""}
	} else {
		p.curToken = p.peekToken
		if p.position+1 < len(p.tokens) {
			p.peekToken = p.tokens[p.position+1]
		} else {
			p.peekToken = token.Token{Type: token.EOF, Literal: ""}
		}
	}
}

// ParseProgram ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã‚’è§£æã™ã‚‹
func (p *Parser) ParseProgram() (*ast.Program, error) {
	program := &ast.Program{
		Statements: []ast.Statement{},
	}

	for p.curToken.Type != token.EOF {
		stmt := p.parseStatement()
		if stmt != nil {
			program.Statements = append(program.Statements, stmt)
		}
		p.nextToken()
	}

	if len(p.errors) > 0 {
		return nil, fmt.Errorf("ãƒ‘ãƒ¼ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: %v", p.errors)
	}

	return program, nil
}

// parseStatement ã¯æ–‡ã‚’è§£æã™ã‚‹
func (p *Parser) parseStatement() ast.Statement {
	switch p.curToken.Type {
	case token.GLOBAL:
		return p.parseGlobalStatement()
	default:
		return p.parseExpressionStatement()
	}
}

// parseGlobalStatement ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°å®£è¨€ã‚’è§£æã™ã‚‹
func (p *Parser) parseGlobalStatement() *ast.GlobalStatement {
	stmt := &ast.GlobalStatement{Token: p.curToken}

	p.nextToken()
	// å‹æƒ…å ±ãŒã‚ã‚Œã°è§£æ
	if p.curTokenIs(token.IDENT) {
		// å‹æƒ…å ±ã‚’å–å¾—
		typeStr := p.curToken.Literal
		p.nextToken()
		stmt.Type = typeStr
	}

	// å¤‰æ•°åã‚’è§£æ
	if !p.curTokenIs(token.IDENT) {
		p.peekError(token.IDENT)
		return nil
	}

	stmt.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
	return stmt
}

// parseExpressionStatement ã¯å¼æ–‡ã‚’è§£æã™ã‚‹
func (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
	stmt := &ast.ExpressionStatement{Token: p.curToken}

	stmt.Expression = p.parseExpression(LOWEST)

	if p.peekTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

// parseExpression ã¯å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseExpression(precedence int) ast.Expression {
	prefix := p.prefixParseFns[p.curToken.Type]
	if prefix == nil {
		p.noPrefixParseFnError(p.curToken.Type)
		return nil
	}
	leftExp := prefix()

	for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
		infix := p.infixParseFns[p.peekToken.Type]
		if infix == nil {
			return leftExp
		}

		p.nextToken()
		leftExp = infix(leftExp)
	}

	return leftExp
}

// parsePipeExpression ã¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePipeExpression(left ast.Expression) ast.Expression {
	// ãƒ‘ã‚¤ãƒ—æ¼”ç®—å­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
	pipeToken := p.curToken
	
	// ãƒ‘ã‚¤ãƒ—æ¼”ç®—å­ã®å„ªå…ˆé †ä½ã‚’å–å¾—
	precedence := p.curPrecedence()
	
	// æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«é€²ã‚€
	p.nextToken()
	
	// ãƒ‘ã‚¤ãƒ—ã®å³å´ã®å¼ã‚’è§£æã™ã‚‹
	// å³å´ã¯é–¢æ•°ã¾ãŸã¯é–¢æ•°å‘¼ã³å‡ºã—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
	rightExp := p.parseExpression(precedence)
	
	// ãƒ‘ã‚¤ãƒ—ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†ã‘ã‚‹
	if pipeToken.Type == token.PIPE {
		// ä¸¦åˆ—ãƒ‘ã‚¤ãƒ— (|) ã®å ´åˆ
		return &ast.InfixExpression{
			Token:    pipeToken,
			Operator: pipeToken.Literal,
			Left:     left,
			Right:    rightExp,
		}
	} else {
		// é€šå¸¸ãƒ‘ã‚¤ãƒ— (|>) ã®å ´åˆ
		// å³è¾ºãŒCallExpressionã‹ã©ã†ã‹ã§å‡¦ç†ã‚’åˆ†ã‘ã‚‹
		if callExp, ok := rightExp.(*ast.CallExpression); ok {
			// æ—¢å­˜ã®å¼•æ•°ãƒªã‚¹ãƒˆã®å…ˆé ­ã« left ã‚’è¿½åŠ 
			callExp.Arguments = append([]ast.Expression{left}, callExp.Arguments...)
			return callExp
		} else {
			// å³è¾ºãŒé–¢æ•°å‘¼ã³å‡ºã—ã§ãªã„å ´åˆã€æ–°ã—ã„é–¢æ•°å‘¼ã³å‡ºã—ã¨ã—ã¦æ‰±ã†
			return &ast.CallExpression{
				Token:     pipeToken,
				Function:  rightExp,
				Arguments: []ast.Expression{left},
			}
		}
	}
}

// parseAssignExpression ã¯ä»£å…¥å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseAssignExpression(left ast.Expression) ast.Expression {
	expression := &ast.InfixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
		Left:     left,
	}

	p.nextToken()
	expression.Right = p.parseExpression(LOWEST)

	return expression
}

// parseIdentifier ã¯è­˜åˆ¥å­ã‚’è§£æã™ã‚‹
func (p *Parser) parseIdentifier() ast.Expression {
	return &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
}

// parseIntegerLiteral ã¯æ•´æ•°ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseIntegerLiteral() ast.Expression {
	lit := &ast.IntegerLiteral{Token: p.curToken}

	value, err := strconv.ParseInt(p.curToken.Literal, 0, 64)
	if err != nil {
		msg := fmt.Sprintf("æ•´æ•° '%s' ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ", p.curToken.Literal)
		p.errors = append(p.errors, msg)
		return nil
	}

	lit.Value = value
	return lit
}

// parseFloatLiteral ã¯æµ®å‹•å°æ•°ç‚¹ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseFloatLiteral() ast.Expression {
	lit := &ast.FloatLiteral{Token: p.curToken}

	value, err := strconv.ParseFloat(p.curToken.Literal, 64)
	if err != nil {
		msg := fmt.Sprintf("æµ®å‹•å°æ•°ç‚¹æ•° '%s' ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ", p.curToken.Literal)
		p.errors = append(p.errors, msg)
		return nil
	}

	lit.Value = value
	return lit
}

// parseStringLiteral ã¯æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseStringLiteral() ast.Expression {
	return &ast.StringLiteral{Token: p.curToken, Value: p.curToken.Literal}
}

// parseBooleanLiteral ã¯çœŸå½å€¤ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseBooleanLiteral() ast.Expression {
	value, err := strconv.ParseBool(p.curToken.Literal)
	if err != nil {
		msg := fmt.Sprintf("çœŸå½å€¤ '%s' ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ", p.curToken.Literal)
		p.errors = append(p.errors, msg)
		return nil
	}
	return &ast.BooleanLiteral{Token: p.curToken, Value: value}
}

// parsePrefixExpression ã¯å‰ç½®å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePrefixExpression() ast.Expression {
	expression := &ast.PrefixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
	}

	p.nextToken()
	expression.Right = p.parseExpression(PREFIX)

	return expression
}

// parseInfixExpression ã¯ä¸­ç½®å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
	expression := &ast.InfixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
		Left:     left,
	}

	precedence := p.curPrecedence()
	p.nextToken()
	expression.Right = p.parseExpression(precedence)

	return expression
}

// parseGroupedExpression ã¯æ‹¬å¼§ã§å›²ã¾ã‚ŒãŸå¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseGroupedExpression() ast.Expression {
	p.nextToken()

	exp := p.parseExpression(LOWEST)

	if !p.expectPeek(token.RPAREN) {
		return nil
	}

	return exp
}

// parseArrayLiteral ã¯é…åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseArrayLiteral() ast.Expression {
	array := &ast.ArrayLiteral{Token: p.curToken}
	array.Elements = p.parseExpressionList(token.RBRACKET)
	return array
}

// parseExpressionList ã¯å¼ã®ãƒªã‚¹ãƒˆã‚’è§£æã™ã‚‹
func (p *Parser) parseExpressionList(end token.TokenType) []ast.Expression {
	list := []ast.Expression{}

	if p.peekTokenIs(end) {
		p.nextToken()
		return list
	}

	p.nextToken()
	list = append(list, p.parseExpression(LOWEST))

	for p.peekTokenIs(token.COMMA) {
		p.nextToken()
		p.nextToken()
		list = append(list, p.parseExpression(LOWEST))
	}

	if !p.expectPeek(end) {
		return nil
	}

	return list
}

// parseIndexExpression ã¯æ·»å­—å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseIndexExpression(left ast.Expression) ast.Expression {
	exp := &ast.IndexExpression{Token: p.curToken, Left: left}

	p.nextToken()
	exp.Index = p.parseExpression(LOWEST)

	if !p.expectPeek(token.RBRACKET) {
		return nil
	}

	return exp
}

// parsePropertyExpression ã¯ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚¢ã‚¯ã‚»ã‚¹å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parsePropertyExpression(left ast.Expression) ast.Expression {
	exp := &ast.PropertyAccessExpression{
		Token:  p.curToken,
		Object: left,
	}

	p.nextToken()
	exp.Property = p.parseExpression(PROPERTY)

	return exp
}

// parseFunctionLiteral ã¯é–¢æ•°ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parseFunctionLiteral() ast.Expression {
	lit := &ast.FunctionLiteral{Token: p.curToken}

	// é–¢æ•°åãŒã‚ã‚Œã°è§£æ
	if p.peekTokenIs(token.IDENT) {
		p.nextToken()
		lit.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
	}

	// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’è§£æ
	if !p.expectPeek(token.LPAREN) {
		return nil
	}
	lit.Parameters = p.parseFunctionParameters()

	// å‹æ³¨é‡ˆãŒã‚ã‚Œã°è§£æ
	if p.peekTokenIs(token.COLON) {
		p.nextToken() // :
		p.nextToken() // å…¥åŠ›å‹
		lit.InputType = p.curToken.Literal

		if p.peekTokenIs(token.MINUS) {
			p.nextToken() // -
			if p.peekTokenIs(token.GT) {
				p.nextToken() // >
				p.nextToken() // å‡ºåŠ›å‹
				lit.ReturnType = p.curToken.Literal
			}
		}
	}

	// æ¡ä»¶ä»˜ãé–¢æ•°å®šç¾©ã®æ¡ä»¶éƒ¨åˆ†ã‚’è§£æ
	if p.peekTokenIs(token.IF) {
		p.nextToken() // if
		p.nextToken()
		lit.Condition = p.parseExpression(LOWEST)
	}

	// é–¢æ•°æœ¬ä½“ã‚’è§£æ
	if !p.expectPeek(token.LBRACE) {
		return nil
	}
	lit.Body = p.parseBlockStatement()

	return lit
}

// parseFunctionParameters ã¯é–¢æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’è§£æã™ã‚‹
func (p *Parser) parseFunctionParameters() []*ast.Identifier {
	identifiers := []*ast.Identifier{}

	if p.peekTokenIs(token.RPAREN) {
		p.nextToken()
		return identifiers
	}

	p.nextToken()

	ident := &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
	identifiers = append(identifiers, ident)

	for p.peekTokenIs(token.COMMA) {
		p.nextToken()
		p.nextToken()
		ident := &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
		identifiers = append(identifiers, ident)
	}

	if !p.expectPeek(token.RPAREN) {
		return nil
	}

	return identifiers
}

// parseCallExpression ã¯é–¢æ•°å‘¼ã³å‡ºã—å¼ã‚’è§£æã™ã‚‹
func (p *Parser) parseCallExpression(function ast.Expression) ast.Expression {
	exp := &ast.CallExpression{Token: p.curToken, Function: function}
	exp.Arguments = p.parseExpressionList(token.RPAREN)
	return exp
}

// parseBlockStatement ã¯ãƒ–ãƒ­ãƒƒã‚¯æ–‡ã‚’è§£æã™ã‚‹
func (p *Parser) parseBlockStatement() *ast.BlockStatement {
	block := &ast.BlockStatement{Token: p.curToken}
	block.Statements = []ast.Statement{}

	p.nextToken()

	for !p.curTokenIs(token.RBRACE) && !p.curTokenIs(token.EOF) {
		stmt := p.parseStatement()
		if stmt != nil {
			block.Statements = append(block.Statements, stmt)
		}
		p.nextToken()
	}

	return block
}

// parseClassLiteral ã¯ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’è§£æã™ã‚‹
func (p *Parser) parseClassLiteral() ast.Expression {
	lit := &ast.ClassLiteral{Token: p.curToken}

	// ã‚¯ãƒ©ã‚¹åã‚’è§£æ
	if !p.expectPeek(token.IDENT) {
		return nil
	}
	lit.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

	// ç¶™æ‰¿ãŒã‚ã‚Œã°è§£æ
	if p.peekTokenIs(token.EXTENDS) {
		p.nextToken() // extends
		if !p.expectPeek(token.IDENT) {
			return nil
		}
		lit.Extends = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
	}

	// ã‚¯ãƒ©ã‚¹æœ¬ä½“ã‚’è§£æ
	if !p.expectPeek(token.LBRACE) {
		return nil
	}

	p.nextToken()

	// ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è§£æ
	for !p.curTokenIs(token.RBRACE) && !p.curTokenIs(token.EOF) {
		if p.curTokenIs(token.PUBLIC) || p.curTokenIs(token.PRIVATE) {
			// ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å®šç¾©
			prop := &ast.PropertyDefinition{
				Token:      p.curToken,
				Visibility: p.curToken.Literal,
			}

			p.nextToken()
			// å‹æƒ…å ±ãŒã‚ã‚Œã°è§£æ
			if p.peekTokenIs(token.IDENT) && !p.peekTokenIs(token.IDENT) {
				prop.Type = p.curToken.Literal
				p.nextToken()
			}

			// ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£åã‚’è§£æ
			if !p.curTokenIs(token.IDENT) {
				p.peekError(token.IDENT)
				return nil
			}
			prop.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
			lit.Properties = append(lit.Properties, prop)
		} else if p.curTokenIs(token.FUNCTION) {
			// ãƒ¡ã‚½ãƒƒãƒ‰å®šç¾©
			method := p.parseFunctionLiteral().(*ast.FunctionLiteral)
			lit.Methods = append(lit.Methods, method)
		} else {
			p.errors = append(p.errors, fmt.Sprintf("ã‚¯ãƒ©ã‚¹å®šç¾©å†…ã§äºˆæœŸã—ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã§ã™: %s", p.curToken.Literal))
		}
		p.nextToken()
	}

	return lit
}

// parsePizzaLiteral ã¯ğŸ•ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parsePizzaLiteral() ast.Expression {
	return &ast.PizzaLiteral{Token: p.curToken}
}

// parsePooLiteral ã¯ğŸ’©ãƒªãƒ†ãƒ©ãƒ«ã‚’è§£æã™ã‚‹
func (p *Parser) parsePooLiteral() ast.Expression {
	return &ast.PooLiteral{Token: p.curToken}
}

// curTokenIs ã¯ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã—ãŸå‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹
func (p *Parser) curTokenIs(t token.TokenType) bool {
	return p.curToken.Type == t
}

// peekTokenIs ã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã—ãŸå‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹
func (p *Parser) peekTokenIs(t token.TokenType) bool {
	return p.peekToken.Type == t
}

// expectPeek ã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã—ãŸå‹ã§ã‚ã‚Œã°æ¬¡ã«é€²ã‚€
func (p *Parser) expectPeek(t token.TokenType) bool {
	if p.peekTokenIs(t) {
		p.nextToken()
		return true
	}
	p.peekError(t)
	return false
}

// peekError ã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸå¾…ã¨ç•°ãªã‚‹å ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’è¿½åŠ ã™ã‚‹
func (p *Parser) peekError(t token.TokenType) {
	msg := fmt.Sprintf("%dè¡Œç›®: æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ %s ã§ã‚ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã¯ %s ã§ã™",
		p.peekToken.Line, t, p.peekToken.Type)
	p.errors = append(p.errors, msg)
}

// noPrefixParseFnError ã¯å‰ç½®è§£æé–¢æ•°ãŒãªã„å ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’è¿½åŠ ã™ã‚‹
func (p *Parser) noPrefixParseFnError(t token.TokenType) {
	msg := fmt.Sprintf("%dè¡Œç›®: ãƒˆãƒ¼ã‚¯ãƒ³ %s ã«å¯¾ã™ã‚‹å‰ç½®è§£æé–¢æ•°ãŒã‚ã‚Šã¾ã›ã‚“",
		p.curToken.Line, t)
	p.errors = append(p.errors, msg)
}

// registerPrefix ã¯å‰ç½®æ¼”ç®—å­ã®è§£æé–¢æ•°ã‚’ç™»éŒ²ã™ã‚‹
func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
	p.prefixParseFns[tokenType] = fn
}

// registerInfix ã¯ä¸­ç½®æ¼”ç®—å­ã®è§£æé–¢æ•°ã‚’ç™»éŒ²ã™ã‚‹
func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
	p.infixParseFns[tokenType] = fn
}

// peekPrecedence ã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å„ªå…ˆé †ä½ã‚’è¿”ã™
func (p *Parser) peekPrecedence() int {
	if p, ok := precedences[p.peekToken.Type]; ok {
		return p
	}
	return LOWEST
}

// curPrecedence ã¯ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å„ªå…ˆé †ä½ã‚’è¿”ã™
func (p *Parser) curPrecedence() int {
	if p, ok := precedences[p.curToken.Type]; ok {
		return p
	}
	return LOWEST
}
